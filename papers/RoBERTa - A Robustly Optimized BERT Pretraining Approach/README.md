* 2024, Phong Nguyen*

<div>
<p align="center">
  <img src="figure1.png" style="width:800px"/>
</p>

<a href='https://arxiv.org/abs/1907.11692'><img src='https://img.shields.io/badge/dynamic/json?url=https://api.semanticscholar.org/graph/v1/paper/077f8329a7b6fa3b7c877a57b81eb6c18b5f87de?fields=citationCount&query=citationCount&label=2019&prefix=citation%20'/></a>

- This paper proposes a number of modification to the training details of BERT and achieves SOTA results in several benchmarks.
- It removes next sentence prediction objective, trains for longer sequences in bigger batches. It also changes the masking pattern the of masked tokens dynamically.

</div>